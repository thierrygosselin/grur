% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/grur_imputations.R
\name{grur_imputations}
\alias{grur_imputations}
\title{Map-independent imputations of missing genotypes}
\usage{
grur_imputations(data, imputation.method = "rf",
  hierarchical.levels = "populations", num.tree = 50,
  pred.mean.matching = 0, verbose = TRUE,
  parallel.core = parallel::detectCores() - 1, random.seed = NULL,
  filename = NULL, ...)
}
\arguments{
\item{data}{A tidy genomic dataset.
It can be file in the working directory or
an object in the global environment.
To get a tidy dataset from various genomic format, see
\href{https://github.com/thierrygosselin/radiator}{radiator}
\code{\link[radiator]{tidy_genomic_data}}.
\emph{See details of this function for more info}.}

\item{imputation.method}{(character, optional)
Methods available for map-independent imputations of missing genotype:

(1) \code{imputation.method = "max"} Strawman imputation,
the most frequently observed genotypes (ties are broken at random).

(2) \code{imputation.method = "rf"} On-the-fly-imputations using
Random Forests algorithm.

(3) \code{imputation.method = "boost"} extreme gradient boosting trees.

(4) \code{imputation.method = "mca"} Multiple Correspondence Analysis.

\code{imputation.method = NULL} will return the original dataset, without
imputation.
Default: \code{imputation.method = "rf"}.}

\item{hierarchical.levels}{(character, optional) \code{c("global", "populations")}.
Should the imputations be computed globally or by populations. Note that
imputing genotype globally in conjunction with \code{imputation.method = "max"}
can create huge bias for example by
introducing foreign genotypes in some populations (see note for more info).
Default: \code{hierarchical.levels = "populations"}.}

\item{num.tree}{(integer, optional) The number of trees to grow
when \code{imputation.method = "rf"} or \code{imputation.method = "rf_pred"}.
Default: \code{num.tree = 50}.}

\item{pred.mean.matching}{(integer, optional) Used in conjunction with
random Forests (\code{imputation.method = "rf_pred"}).
Number of candidate non-missing
value to sample from during the predictive mean matching step.
A fast k-nearest neighbor searching algorithms is used with this approach.
\code{pred.mean.matching = 3} will use 3 neighbors.
Default: \code{pred.mean.matching = 0}, avoids this step.}

\item{verbose}{(optional, logical) When \code{verbose = TRUE}
the function is a little more chatty during execution.
Default: \code{verbose = TRUE}.}

\item{parallel.core}{(optional) The number of core used for parallel
execution when \code{imputation.method = "rf"}.
Markers are imputed in parallel, populations are processed sequentially.
Default: \code{parallel::detectCores() - 1}.}

\item{random.seed}{(integer, optional) For reproducibility, set an integer
that will be used to initialize the random generator. With default,
a random number is generated.
Default: \code{random.seed = NULL}.}

\item{filename}{(optional) The file name for the \strong{imputed}
tidy data frame written to the working directory.
With missing argument or default: \code{filename = NULL}, the imputed
tidy data is in the global environment only
(i.e. not written in the working directory).}

\item{...}{(optional) To pass further argument for fine-tuning your
imputations. See details below.}
}
\value{
The output in your global environment is the imputed tidy data frame.
If \code{filename} is provided, the imputed tidy data frame is also
written to the working directory. The original data is returned for markers
with \emph{all} or \emph{no} NA.
}
\description{
Used internally in \href{https://github.com/thierrygosselin/assigner}{assigner} and
\href{https://github.com/thierrygosselin/radiator}{radiator} and
might be of interest for users.
The goal of this module is to provide a simple solution for
a complicated problem: missing genotypes in RADseq genomic datasets.
This function will performed \strong{map-independent imputations} of missing
genotypes.

\strong{Key features:}

\itemize{
\item \strong{Imputation algorithms/methods: } Random forests (on-the-fly-imputation, ),
Extreme gradient tree boosting,
Multiple Correspondence Analysis (MCA) and
the classic Strawman imputation
(~ max/mean/mode: the most frequently observed, i.e. non-missing, genotypes is used).
\item \strong{Hierarchical level: } Imputations conducted by populations or globally.
\item \strong{Haplotype/SNP approach: } Correlation among SNPs is accounted for during
rf and tree boosting imputation, i.e. imputation is automatically conducted by haplotype
when marker meta-information is avaialble (chromosome, locus and position,
usually from VCF files). The alternative, considers all the markers independent
and imputation is conducted by SNPs.
\item \strong{Genotype likelihood (GL): } The GL info is detected automatically
(GL column in FORMAT field of VCF files). Genotypes with higher likelihood
will have higher probability during bootstrap samples of trees in Random
forests.
Notes: (1) option only available with Random forests;
(2) the use of genotype likelihoods
in the form of normalized, phred-scaled likelihoods (PL, e.g. from GATK)
are not recognized, yet... it's still under development.
\item \strong{Predictive mean matching: } the rf option uses a fast k-nearest neighbor
(KNN) searching algorithms (see argument documentation and details below).
\item \strong{Optimized for speed: } the package
\href{https://github.com/imbs-hl/ranger}{ranger}
(see Wright and Ziegler, 2016) provides a fast C++ version
of the original implementation of rf from Breiman (2001).
The \href{https://github.com/dmlc/xgboost}{XGBoost} provides the fast C++
implementation for the extreme gradient tree boosting algorithm.
Imputations of genotypes are conducted in parallel across CPUs.
A progress bar is now available to see if you have time for a coffee break!
}


Before running this function to populate the original dataset with synthetic
data I highly recommend you look for patterns of missingness
\code{\link[grur]{missing_visualization}}
and explore the reasons for their presence.
Follow the \href{https://www.dropbox.com/s/4zf032g6yjatj0a/vignette_missing_data_analysis.nb.html?dl=0}{vignette}
for more info.
}
\details{
\strong{Predictive mean matching:}

Random Forests already behave like a nearest neighbor
classifier, with adaptive metric. Now we have the option to conduct
predictive mean matching on top of the prediction based missing value
imputation.PMM tries to raise the variance in the resulting conditional
distributions to a realistic level.
The closest k predicted values are identified by a fast
k-nearest neighbour approach wrapped in the package
\href{https://github.com/mayer79/missRanger}{missRanger}
Returned value correspond to the mean value.


\strong{haplotype/SNP approach:}

The \emph{haplotype approach} is automatically used when markers meta-information
is detected (chromosome/CHROM, locus/ID and SNP/POS columns, usually from a VCF file).
Missing genotypes from SNPs on the same locus or same RADseq read is undertaken
simulteneously to account for the correlation of the linked SNPs. When one or
more SNPs on the same read/haplotype is missing, the haplotype is deleted and
consequently, imputation might results in different genotype for those SNPs
that were not missing. This approach is much safer than potentially creating
weird chimeras during haplotype imputations.
Alternatively, a \emph{snp approach} is used, and the SNP are considered
independent. Imputations of genotypes is then conducted for each marker separately.


\strong{Imputing globally or by populations ?}
\code{hierarchical.levels = "global"} argument will act differently depending
on the \code{imputation.method} selected.

\strong{Strawman imputations (~ max/mean/mode) considerations: }

With \code{imputation.method = "max"} and \code{hierarchical.levels = "global"}
\emph{will likely create bias}.

\emph{Example 1 (unbalanced sample size):} Consider 2 populations evolving more
by drift than selection: pop1 (n = 36) and pop2 (n = 50).
You'll likely have a few polymorphic marker, where pop1 and pop2 are
monomorphic for different alleles (pop1 is fixed for the minor/ALT allele and
pop2 is fixed for the major/REF allele). Missing genotypes in pop1
using the most common filling technique in the literature (using mean/mode/max),
will result in pop1 having individuals with the REF allele.
Not something you want... unless your population membership is not 100% accurate,
(e.g. you might have migrants or wrong assignation),
which in this case you still don't want to impute with
\code{imputation.method = "max"} (see alternative below).

\emph{Example 2 (balanced sample size):} pop1 (n = 100) and pop2 (n = 100).
For a particular marker, pop1 as 85 individuals genotyped and pop2 100.
Again, if the populations are fixed for different alleles
(pop1 = ALT and pop2 = REF), you will end up having REF allele in your pop1,
not something you want... unless your population membership is not 100% accurate,
(e.g. you might have migrants or wrong assignation),
which in this case you still don't want to impute with
\code{imputation.method = "max"} (see alternative below).

\strong{Random Forests imputations: }

Random Forests use machine learning and you can take this into account while
choosing argument values. Uncertain of the groupings ? Use random forests with
\code{hierarchical.levels = "global"}. Random forests will account for the
potential linkage and correlation between
markers and genotypes to make the best imputation available. This can potentially
results in genotypes for a certain combo population/marker with new groupings
(e.g. a new allele). This is much more accurate and not the same thing as
the \code{imputation.method = "max"} because the imputed genotype was validated
after considering all the other genotype values of the individual being imputed.
\emph{Test the option and report bug if you find one.}

\emph{random forest with on-the-fly-imputation (rf): }the technique is described
in Tang and Ishwaran (2017). Non-missing genotypes are used for
the split-statistics. Daughter node assignation membership use random
non-missing genotypes from the inbag data. Missing genotypes are imputed at
terminal nodes using maximal class rule with out-of-bag non-missing genotypes.

\emph{random forest as a prediction problem (rf_pred): }markers with
missing genotypes are imputed one at a time. The fitted forest is used to
predict missing genotypes. Missingness in the response variables are
incorporated as attributes for growing the forest.

\strong{... :dot dot dot arguments}

The argument is available to tailor your imputations using
extreme gradient tree boosting and random forest:

Available arguments for extreme gradient tree boosting tree method:
\emph{eta, gamma, max_depth, min_child_weight, subsample, colsample_bytree,
num_parallel_tree, nrounds, save_name, early_stopping_rounds}.
Refer to \code{\link[xgboost]{xgboost}} for arguments documentation.


Available arguments for Random forests method:
\emph{nodesize, nsplit, nimpute}.
Refer to \code{\link[randomForestSRC]{impute.rfsrc}} for arguments documentation.
}
\note{
\strong{Reference genome or linkage map available ?}

Numerous approaches are available and more appropriate, please search
the literature
(\href{https://online.papersapp.com/collections/05d6e65a-73c9-49e6-9c75-289a818f76f3/share}{references}).


\strong{What's simple imputation message when running the function ?}

Before conducting the imputations by populations with random forest or extreme
gradient tree boosting, the data is first screened for markers that are
monomorphic within populations. Because for those cases, it's clear what the
missing genotypes should be, the imputations is very \emph{simple} and missing
genotypes are imputed with the only genotype found for the particular population.
The small cost in time is worth it, because the random forest or extreme
gradient tree boosting model will benefit having more complete and
reliable genotypes.


\strong{Deprecated arguments:}

\itemize{
\item \code{imputations.group} is now replaced by \code{hierarchical.levels}
\item \code{impute} is no longer available.
Imputing using \code{impute = "allele"} option was wrong because it
was using F1 genotypes for imputations. Now imputation is only conducted at
the genotype level.
\item \code{iteration.rf} is no longer used. This argument is now available
inside the \code{...} for on-the-fly-imputations (see details). The default
is now set to 10 iterations.
\item \code{split.number} is automatically set.
}
}
\examples{
\dontrun{
# The simplest way to run when you have a tidy dataset:

wolf.imputed <- grur::grur_imputations(data = "wolf.tidy.dataset.tsv")

# This will impute the missing genotypes by population using random Forests.
# The remaining arguments will be the defaults.

# When you start with a vcf file you can use magrittr \%>\% to `pipe` the
# result. Below, an example with more arguments offered by the functions:

wolf.imp <- radiator::tidy_genomic_data(
    data = "batch_1.vcf",
    strata = "strata.wolf.10pop.tsv",
    vcf.metadata = TRUE,
    whitelist.markers = "whitelist.loci.txt",
    verbose = TRUE) \%>\%
grur::grur_imputations(
    data = ., imputation.method = "boost", parallel.core = 32)
}
}
\references{
Wright, M. N. & Ziegler, A. (2016).
ranger: A Fast Implementation of Random Forests for High Dimensional Data
in C++ and R.
Journal of Statistical Software, in press. http://arxiv.org/abs/1508.04409.

Breiman, L. (2001). Random forests. Machine learning, 45(1), 5-32.

Chen T, Guestrin C. (2016).
XGBoost: A scalable tree boosting system. arXivorg. 2016.
doi:10.1145/2939672.2939785

Tang F, Ishwaran H. (2017) Random Forest Missing Data Algorithms.
arXiorg: 1–24.
}
\seealso{
\href{https://github.com/mayer79/missRanger}{missRanger}

\href{https://github.com/imbs-hl/ranger}{ranger}

\href{https://github.com/stekhoven/missForest}{missForest}

\href{https://github.com/kogalur/randomForestSRC}{randomForestSRC}

\href{https://github.com/dmlc/xgboost}{XGBoost}
}
\author{
Thierry Gosselin \email{thierrygosselin@icloud.com}
}
